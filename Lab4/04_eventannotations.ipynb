{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will transform some annotation data into a format useful for training a frame-based \"event detection\" or \"transcription\" system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION 1: Using the variables given below, calculate (and store in a new variable) the time step in seconds, from one spectrogram frame to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplerate = 22050    # in Hertz (1/second)\n",
    "fftlength = 1024      # in samples (unitless)\n",
    "hop = 0.5             # a ratio (unitless)\n",
    "\n",
    "hop_len = ... # hop length\n",
    "hop_size_s = ... # hop length in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load the CSV annotation data (code provided):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...first you will need to extract an annotation file. We've provided it, but it is in a Zip file. You'll need to unzip the CSV files first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will unzip the data into a folder NEXT TO wherever this notebook file is stored.\n",
    "\n",
    "!unzip -n \"/home/jovyan/shared_storage/ECS7013P/nips4bplus/temporal_annotations_nips4b.zip\"\n",
    "\n",
    "# The above should work on the jhub server.\n",
    "# If not on jhub server, you could download the dataset from:\n",
    "#      https://figshare.com/articles/Transcriptions_of_NIPS4B_2013_Bird_Challenge_Training_Dataset/6798548"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotpath = \"temporal_annotations_nips4b/annotation_train001.csv\"\n",
    "\n",
    "import csv, numpy\n",
    "\n",
    "def processrow(arow):\n",
    "    \"This function takes a data row from text CSV, and converts data types\"\n",
    "    # the raw CSV format is starttime, duration, class\n",
    "    return {\n",
    "        'start': float(arow[0]),\n",
    "        'dur':   float(arow[1]),\n",
    "        'class': arow[2],\n",
    "    }\n",
    "\n",
    "# Now we do the actual loading, and process the CSV file line by line\n",
    "with open(annotpath, 'r') as infp:\n",
    "    rdr = csv.reader(infp)\n",
    "    annots = [processrow(row) for row in rdr]\n",
    "    \n",
    "#print(\"Some of the data:\")\n",
    "#for entry in annots[:5]:\n",
    "print(\"The data:\")\n",
    "for entry in annots:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for convenience, this block is to load the list of classes from the CSV file and build 2 maps: classname --> classid and classid --> classname\n",
    "# you should view the file to see how it looks\n",
    "class_list_path = \"/home/jovyan/shared_storage/ECS7013P/nips4bplus/nips4b_birdchallenge_espece_list.csv\"\n",
    "classname2id = {} # classname --> classid map\n",
    "id2classname = {} # classid --> classname map\n",
    "with open(class_list_path, 'r') as infp:\n",
    "    rdr = csv.reader(infp)\n",
    "    next(rdr, None)  # skip the headers\n",
    "    next(rdr, None)  # skip the first line with \"Empty\" class \n",
    "    for row in rdr:\n",
    "        classname2id[row[1]] = int(row[0]) # map class name to class id\n",
    "        id2classname[int(row[0])] = row[1] # map class id to class name\n",
    "classname2id[\"Unknown\"] = len(classname2id) # handle additional \"Unknown\" class\n",
    "id2classname[len(id2classname)] = \"Unknown\" # handle additional \"Unknown\" class\n",
    "\n",
    "print(\"Some of the data:\")\n",
    "print(\"Butbut_call\" + \" -> \" + str(classname2id[\"Butbut_call\"]))\n",
    "print(\"Erirub_call\" + \" -> \" + str(classname2id[\"Erirub_call\"]))\n",
    "print(\"4\" + \" -> \" + id2classname[4])\n",
    "print(\"22\" + \" -> \" + id2classname[22])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION 2: Now, using the time step variable that you calculated above, write some code that will take the annotation data and convert it into a numpy matrix of ones and zeros.\n",
    "\n",
    "The dimensions of the matrix should represent (#frame, #class) where #frame is the number of time frames and #class is the number of classes. The matrix should have a 1 where each class is active at that time frame and 0 where it is not.\n",
    "\n",
    "__Hints__: \n",
    "- The maximum length of an audio file is __5 seconds__, you should use this to calculate #frame.\n",
    "- Using the time step variable that you calculated in QUESTION 1 to calculate __frame rate__ (i.e. the number of frames in one second) from which a time in seconds can be converted to a time frame index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "audio_max_len_samples = 5*samplerate # each audio file is 5 seconds\n",
    "max_frames = ... # maximum number of frames per audio file\n",
    "num_classes = ... # number of classes\n",
    "\n",
    "frame_rate = ... # frame rate\n",
    "\n",
    "annotation_matrix = numpy.zeros((max_frames, num_classes))\n",
    "\n",
    "for entry in annots: # iterate the annotation one by one\n",
    "    # COMPLETE YOUR CODE HERE\n",
    "    \n",
    "# try to visualize annotation matrix\n",
    "plt.imshow(annotation_matrix,aspect='auto', origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QUESTION 3: Once you have done the above, write some code that does the opposite - i.e. converts an annotation matrix back into a list of events given with start time, end time and class label. (This is the kind of post-processing we might do with the *output* from an event detection system.)\n",
    "\n",
    "__Hints__: For each column (corresponding to one class), find the indices of non-zeros entries (you can use `numpy.where` function for this), then find chunks of continuous numbers in the list of indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = list() # the list to store the annotation\n",
    "\n",
    "# COMPLETE YOUR CODE HERE\n",
    "        \n",
    "print(\"Some of the data:\")\n",
    "for entry in output_dict:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QEUSTION 4: Compare the original annotations (as loaded) against the annotations produced when you apply your conversion followed by your back-conversion. Are there differences? Of what kind?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The order\n",
    "- Some differences in the time values due to rounding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
